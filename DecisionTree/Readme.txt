基础概念:
1、信息增益：划分数据集之前和之后信息发生的变化，获得信息增益最高的特征就是最好的选择
	特征A对训练数据集D的信息增益g（D,A）定义为集合D的经验熵H（D）与特征A给定条件下
	D的经验熵H（D|A）之差，即g（D，A）=H（D）-H（D|A）
2、熵：信息的期望值，随机变量不确定性的度量
	参考《统计学习方法》60页
3、损失函数：在假设空间F中选取模型f作为决策函数，对于给定的输入X，由f（X）给出相应的输出Y
	这个输出的预测值f（X）与真实值Y可能一致也可能不一致，用一个损失函数或代价函数来
	度量预测错误的程度，损失函数是f（X）和Y的非负实值函数，记作L（Y，f（X））
决策树的生成：
1、ID3算法
	方法：从根结点开始，对结点计算所有可能的特征的信息增益，选择信息增益最大的特征作为
	结点的特征，由该特征的不同取值建立子节点；再对子节点调用以上方法，构建决策树；直到
	所有特征的信息增益均很小或没有特征可以选择为止。最后得到一个决策树。
2、C4.5算法
	方法：与ID3算法相似，用信息增益比来选择特征

决策树的剪枝：
1、决策树的剪枝通过极小化决策树的整体损失函数或代价函数来实现


CART生成：
1、回归树：采用平方误差最小化准则
2、分类树：采用尼基指数最小化准则

CART剪枝：